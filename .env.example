# ForecastLabAI Environment Configuration
# Copy this file to .env and adjust values as needed

# Database connection (PostgreSQL + pgvector via Docker Compose)
DATABASE_URL=postgresql+asyncpg://forecastlab:forecastlab@localhost:5433/forecastlab

# Application settings
APP_NAME=ForecastLabAI
APP_ENV=development
DEBUG=true
LOG_LEVEL=INFO
LOG_FORMAT=json

# API settings
API_HOST=0.0.0.0
API_PORT=8123

# Forecasting settings
FORECAST_RANDOM_SEED=42
FORECAST_DEFAULT_HORIZON=14
FORECAST_MAX_HORIZON=90
FORECAST_MODEL_ARTIFACTS_DIR=./artifacts/models
FORECAST_ENABLE_LIGHTGBM=false

# RAG Configuration
# Embedding Provider: "openai" or "ollama"
RAG_EMBEDDING_PROVIDER=openai

# OpenAI Configuration (when RAG_EMBEDDING_PROVIDER=openai)
OPENAI_API_KEY=sk-your-openai-api-key-here
RAG_EMBEDDING_MODEL=text-embedding-3-small

# Ollama Configuration (when RAG_EMBEDDING_PROVIDER=ollama)
# OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Embedding dimension (must match your model: OpenAI=1536, nomic-embed-text=768, etc.)
RAG_EMBEDDING_DIMENSION=1536
RAG_EMBEDDING_BATCH_SIZE=100

# Chunking settings
RAG_CHUNK_SIZE=512
RAG_CHUNK_OVERLAP=50
RAG_MIN_CHUNK_SIZE=100

# Retrieval settings
RAG_TOP_K=5
RAG_SIMILARITY_THRESHOLD=0.7
RAG_MAX_CONTEXT_TOKENS=4000

# pgvector index settings
RAG_INDEX_TYPE=hnsw
RAG_HNSW_M=16
RAG_HNSW_EF_CONSTRUCTION=64

# =============================================================================
# Agentic Layer Configuration (PydanticAI v1.48.0)
# =============================================================================

# Model Configuration
# Model identifier format: "provider:model-name"
# Supported providers:
#   - anthropic: Claude models (claude-sonnet-4-5, claude-opus-4-5, etc.)
#   - openai: GPT models (gpt-4o, gpt-4o-mini, etc.)
#   - google-gla: Gemini models via Google AI Studio (gemini-2-5-flash, gemini-3-flash, gemini-3-pro)
#   - google-vertex: Gemini models via Vertex AI (gemini-*) [requires GCP auth]
AGENT_DEFAULT_MODEL=anthropic:claude-sonnet-4-5
AGENT_FALLBACK_MODEL=openai:gpt-4o

# API Keys (only one needed based on your chosen provider)
ANTHROPIC_API_KEY=sk-ant-your-anthropic-api-key-here
# OPENAI_API_KEY=sk-your-openai-api-key-here
# GOOGLE_API_KEY=your-google-api-key-here  # For google-gla:* models

# Gemini Extended Reasoning (optional)
# Thinking mode for Gemini 2.5+ models (requires additional tokens)
# Set a token budget (e.g., 2000-8000) or leave unset to disable
# Recommended: 4000 tokens for complex agent planning tasks
# AGENT_THINKING_BUDGET=4000

# Model parameters
AGENT_TEMPERATURE=0.1
AGENT_MAX_TOKENS=4096

# Execution settings
AGENT_MAX_TOOL_CALLS=10
AGENT_TIMEOUT_SECONDS=120
AGENT_RETRY_ATTEMPTS=3
AGENT_RETRY_DELAY_SECONDS=1.0

# Session settings
AGENT_SESSION_TTL_MINUTES=120
AGENT_MAX_SESSIONS_PER_USER=5

# Human-in-the-loop actions (JSON array format required for safe parsing)
AGENT_REQUIRE_APPROVAL=["create_alias","archive_run"]
AGENT_APPROVAL_TIMEOUT_MINUTES=60

# Streaming
AGENT_ENABLE_STREAMING=true

# Frontend (Vite)
VITE_API_BASE_URL=http://localhost:8123
